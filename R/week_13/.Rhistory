motor_details
#motor_data <- read_html('https://www.motorcycle.com/specs/kawasaki/sport/2009/ninja/250r/detail.html')
motor_data <- read_html(url)
motor_details <- list()
motor_details[["name"]] <- motor_data %>% html_nodes('.sl-post-title') %>% html_text()
key <- motor_data %>% html_nodes('.spec-key.bold') %>% html_text()
value <- motor_data %>% html_nodes('.vs-specs-table-row .spec-value') %>% html_text()
if(length(key)==length(value)){
for (i in 1:length(key)) {
motor_details[[key[i]]] <- value[i]
}
return(motor_details)
}
return(motor_details)
if(length(key)==length(value)){
for (i in 1:length(key)) {
motor_details[[key[i]]] <- value[i]
}
return(motor_details)
}
get_motors_details('https://www.motorcycle.com/specs/kawasaki/sport/2009/ninja/250r/detail.html')
View(motor_details)
if(length(key)==length(value)){
for (i in 1:length(key)) {
motor_details[[key[i]]] <- value[i]
}
return(motor_details)
}
get_motors_details('https://www.motorcycle.com/specs/kawasaki/sport/2009/ninja/250r/detail.html')
print(get_motors_details('https://www.motorcycle.com/specs/kawasaki/sport/2009/ninja/250r/detail.html'))
View(get_motors_details('https://www.motorcycle.com/specs/kawasaki/sport/2009/ninja/250r/detail.html'))
if(length(key)==length(value)){
for (i in 1:length(key)) {
motor_details[[key[i]]] <- value[i]
}
return(motor_details)
}
get_motors_details <- function(url) {
#motor_data <- read_html('https://www.motorcycle.com/specs/kawasaki/sport/2009/ninja/250r/detail.html')
motor_data <- read_html(url)
motor_details <- list()
motor_details[["name"]] <- motor_data %>% html_nodes('.sl-post-title') %>% html_text()
key <- motor_data %>% html_nodes('.spec-key.bold') %>% html_text()
value <- motor_data %>% html_nodes('.vs-specs-table-row .spec-value') %>% html_text()
if(length(key)==length(value)){
for (i in 1:length(key)) {
motor_details[[key[i]]] <- value[i]
}
return(motor_details)
}
}
View(get_motors_details('https://www.motorcycle.com/specs/kawasaki/sport/2009/ninja/250r/detail.html'))
one_link
#return(relative_link)
class(relative_link)
relative_link <- gsub('#UserReviews','',relative_link)
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
# The midterm project is that you have to scrape all the Kawasaki motor data.
# https://www.motorcycle.com/specs/kawasaki.html
# Make some visualization with the Generic Type (Primary), year, and another interesting variable.
library(rvest)
# 1 get all the link. save it
vector_of_all_links <- c()
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
}
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
# The midterm project is that you have to scrape all the Kawasaki motor data.
# https://www.motorcycle.com/specs/kawasaki.html
# Make some visualization with the Generic Type (Primary), year, and another interesting variable.
library(rvest)
# 1 get all the link. save it
vector_of_all_links <- c()
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
}
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
}
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
vector_of_all_links[1]
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
# The midterm project is that you have to scrape all the Kawasaki motor data.
# https://www.motorcycle.com/specs/kawasaki.html
# Make some visualization with the Generic Type (Primary), year, and another interesting variable.
library(rvest)
# 1 get all the link. save it
vector_of_all_links <- c()
# 1 get all the link. save it
vector_of_all_links <- c()
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
}
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
}
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
one_link
one_link
vector_of_all_links
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
relative_link <- gsub('#UserReviews','',relative_link)
return(relative_link)
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
relative_link <- gsub('#UserReviews','',relative_link)
return(relative_link)
}
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
vector_of_all_links
relative_link
relative_link
# The midterm project is that you have to scrape all the Kawasaki motor data.
# https://www.motorcycle.com/specs/kawasaki.html
# Make some visualization with the Generic Type (Primary), year, and another interesting variable.
library(rvest)
# 1 get all the link. save it
vector_of_all_links <- c()
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
relative_link <- gsub('#UserReviews','',relative_link)
return(relative_link)
}
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
relative_link <- gsub('#UserReviews','',relative_link)
return(relative_link)
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
relative_link <- gsub('#UserReviews','',relative_link)
return(relative_link)
}
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
vector_of_all_links
vector_of_all_links
vector_of_all_links
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
vector_of_all_links <- c()
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
relative_link <- gsub('#UserReviews','',relative_link)
return(relative_link)
}
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
one_link
vector_of_all_links
# 1 get all the link. save it
vector_of_all_links <- c()
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
}
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
vector_of_all_links
vector_of_all_links
one_link
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
# 1 get all the link. save it
vector_of_all_links <- c()
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
#relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
}
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
return(relative_link)
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
#relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
}
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
one_link <- vector_of_all_links[1] # check the link will be correct
one_link
vector_of_all_links
one_link
one_link <- vector_of_all_links[1] # check the link will be correct
vector_of_all_links
library(rvest)
# 1 get all the link. save it
vector_of_all_links <- c()
get_all_links <- function(pageNum) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
#relatvie_link <- paste0('https://www.motorcycle.com', relative_link)
return(relative_link)
}
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
for (pageNum in 1:3) {
get_all_links(pageNum)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
one_link <- vector_of_all_links[1] # check the link will be correct
one_link <- vector_of_all_links[1]
one_link
vector_of_all_links
setwd("~/greenFox/CEU-Traning/R/week_11")
ggplot(df, aes(year, fill =Type, colour = Type)) +
geom_density() +
xlim(2004, 20012)
library(rvest)
library(data.table)
library(kableExtra)
library(dplyr)
# 1 get all the link. save it
vector_of_all_links <- c()
# we target from page1-3 for reload and work faster
for (pageNum in 1:3) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
### 2- createing a function that takes one link, and return with a list, which contain all the data of the motor.
```{r echo=TRUE,warning=FALSE, message= FALSE}
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
vector_of_all_links <- append( vector_of_all_links, relative_link)
# we target from page1-3 for reload and work faster
for (pageNum in 1:3) {
url <- paste0("https://www.motorcycle.com/specs/kawasaki.html?page_num=", pageNum)
t <- read_html(url)
relative_link <- t %>% html_nodes('.flex-one a') %>% html_attr('href')
relative_link <- gsub('#UserReviews','',relative_link)
vector_of_all_links <- append( vector_of_all_links, relative_link)
}
get_motors_details <- function(url) {
motor_data <- read_html(paste0('https://www.motorcycle.com',url))
motor_details <- list()
motor_details[["Title"]] <- motor_data %>% html_nodes('.sl-post-title') %>% html_text()
key <- motor_data %>% html_nodes('.spec-key.bold') %>% html_text() %>% trimws()
value <- motor_data %>% html_nodes('.vs-specs-table-row .spec-value') %>% html_text() %>% trimws()
if(length(key)==length(value)){
for (i in 1:length(key)) {
motor_details[[key[i]]] <- value[i]
}
}
return(motor_details)
}
read_all_links <- lapply(vector_of_all_links, get_motors_details)
# convert to data.frame
motors_df <- rbindlist(read_all_links, fill = T)
# Saving our data as .RDS file for avoiding the 404/402 Error from Server
saveRDS(motors_df,'motors_data.rds')
library(kableExtra)
table <- readRDS('/Users/JM/greenFox/CEU-Traning/R/week_11/motors_data.rds' )
table %>%
kable(booktabs = TRUE) %>%
kable_paper("hover",font_size = 9) %>%
row_spec(0, bold = T, color = 'white',background = "black") %>%
column_spec(1, bold = TRUE, border_right = TRUE, color = "black", background = "lightgrey") %>%
scroll_box(width = "100%", height = "650px")
library(rvest)
library(dplyr)
#df <- readRDS('/Users/JM/greenFox/CEU-Traning/R/week_11/motors_data.rds' )
df <- motors_df
names(df)[11]<-"Name"
names(df)[2]<-"Type"
names(df)[3]<-"Price"
names(df)[5]<-"Warranty"
Year <- df$Year
df$Price<-gsub("\\$","",df$Price) # delete the $ sign
df$Price<-gsub("\\,","",df$Price) # delete the , sign
df$Price<- as.numeric(as.character(df$Price)) # convert the string to number
View(df)
library(ggplot2)
ggplot(df, aes(x=Name, y=Price))+
geom_col(color="grey", fill="black")+
theme_bw()+
coord_flip()+
theme(axis.text.x = element_text(angle =60, vjust=0.5,hjust=0.5))+
labs(x="Name",y="Price", title = "Kawasaki Details")
ggplot(df, aes(year, fill =Type, colour = Type)) +
geom_density() +
xlim(2004, 20012)
ggplot(df, aes(Price, fill =Type, colour = Type)) +
geom_density() +
xlim(2004, 20012)
ggplot(df, aes(Price, fill =Type, colour = Type)) +
geom_density(alpha = 0.1) +
xlim(2004, 20012)
ggplot(df, aes(Price, fill =Type, colour = Type)) +
geom_density(alpha = 0.2) +
xlim(2004, 20012)
View(df)
ggplot(df, aes(Price, fill =Type, colour = Type)) +
geom_density(alpha = 0.2) +
xlim()
ggplot(df, aes(Price, fill =Type, colour = Type)) +
geom_density(alpha = 0.2) +
xlim(2004, 20012)
ggplot(df, aes(Price, fill =Type, colour = Type)) +
geom_density(alpha = 0.2) +
xlim(2000, 30000)
ggplot(df, aes(Price, fill =Type, colour = Type)) +
geom_density(alpha = 0.2) +
xlim(1000, 30000)
library(ggplot2)
library(dplyr)
library(gganimate)
library(hrbrthemes)
library(viridis)
library(gifski)
df_3 <- df %>%
select(Name,Price,Type) %>%
group_by(Type) %>%
arrange(-Price) %>%
head(50)
ggplot( aes(x=Type, y=Price, group=Type, color=Type), data = df_3)+
geom_line()+
geom_point()+
#transition_states(x) +
scale_color_viridis(discrete = TRUE) +
ggtitle("Price of the Kawasaki models") +
theme_ipsum() +
coord_flip()+
theme(axis.text.x = element_text(angle =60, vjust=0.5,hjust=0.5))
# Render the animation
#anim <- animate(df_3, nframes = 10)
# Save the animation
#anim_save("animation.gif", anim, renderer = gifski_renderer())
df_2 <- df %>%
select(Name,Price,Type, Year, Warranty) %>%
group_by(Type) %>%
arrange(Price)
number_of_bar <- nrow(df_2)
angle <-  90 - 360 * (df_2$Price-0.5) /number_of_bar # ? we should have numaric value for price to have right chart
df_2$hjust<-ifelse( angle < -90, 1, 0)
df_2$angle<-ifelse(angle < -90, angle+180, angle)
# -----------------------------
ggplot(df_2, aes(x=Name, y=Price)) +
geom_bar(stat="identity", fill=alpha("blue", 0.3)) +
ylim(-28000,35000) +
theme_minimal() +
theme(
axis.text = element_blank(),
axis.title = element_blank(),
panel.grid = element_blank(),
plot.margin = unit(rep(-2,4), "cm")     # This remove unnecessary margin around plot
) +
coord_polar(start = 0)+
geom_text(data=df_2, aes(x=Name, y=Price, label=Name, hjust=hjust), color="black", fontface="bold",alpha=0.4, size=2, angle= df_2$angle, inherit.aes = FALSE )
df_2 <- df %>%
select(Name,Price,Type, Year, Warranty) %>%
group_by(Type) %>%
arrange(Price)
number_of_bar <- nrow(df_2)
angle <-  90 - 360 * (df_2$Price-0.5) /number_of_bar # ? we should have numaric value for price to have right chart
df_2$hjust<-ifelse( angle < -90, 1, 0)
df_2$angle<-ifelse(angle < -90, angle+180, angle)
# -----------------------------
ggplot(df_2, aes(x=Name, y=Price)) +
geom_bar(stat="identity", fill=alpha("blue", 0.3)) +
ylim(-28000,35000) +
theme_minimal() +
theme(
axis.text = element_blank(),
axis.title = element_blank(),
panel.grid = element_blank(),
# plot.margin = unit(rep(-2,4), "cm")     # This remove unnecessary margin around plot
) +
coord_polar(start = 0)+
geom_text(data=df_2, aes(x=Name, y=Price, label=Name, hjust=hjust), color="black", fontface="bold",alpha=0.4, size=2, angle= df_2$angle, inherit.aes = FALSE )
setwd("~/greenFox/CEU-Traning/R/week_13")
